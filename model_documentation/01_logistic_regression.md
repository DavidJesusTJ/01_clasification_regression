# <center><b> Regresi√≥n Log√≠stica </b></center>

---

## <b>¬øQu√© es?</b>

La **regresi√≥n log√≠stica** es un modelo que se utiliza para **clasificar casos en dos o m√°s categor√≠as posibles** (por ejemplo, ‚Äús√≠‚Äù o ‚Äúno‚Äù, ‚Äúcompra‚Äù o ‚Äúno compra‚Äù, ‚Äúenfermo‚Äù o ‚Äúsano‚Äù).

Lo que hace este modelo es tomar un conjunto de caracter√≠sticas (como edad, ingresos, comportamiento, etc.) y **estimar la probabilidad de que algo ocurra**.

Es especialmente √∫til cuando queremos responder preguntas como:

- ¬øUn cliente dejar√° de usar el servicio?
- ¬øUn paciente tiene una enfermedad?
- ¬øEste correo es spam?

Aunque se llama ‚Äúregresi√≥n‚Äù, en realidad **no predice valores num√©ricos continuos**, sino **probabilidades** que luego se pueden usar para tomar decisiones de clasificaci√≥n.

---

## <b>Formulaci√≥n Matem√°tica</b>

### **Binaria**

Imagina que queremos predecir si un cliente pagar√° o no pagar√° un pr√©stamo.

La regresi√≥n log√≠stica no predice directamente 0 o 1, sino la probabilidad de que ocurra el evento (por ejemplo, que s√≠ pague).

La f√≥rmula con variables $X = (x_1, ..., x_p)$ es:

$$
P(Y = 1 \mid X) = \sigma(z) = \frac{1}{1 + e^{-z}}, \quad \text{donde } z = \beta_0 + \beta_1 x_1 + \dots + \beta_p x_p
$$

La funci√≥n $\sigma(z)$ es la **sigmoide**. Cuanto mayor $z$, m√°s cercana a 1 ser√° la probabilidad.

¬øQu√© significa eso?

* Tomamos una combinaci√≥n lineal de las variables (edad, ingresos, etc.) ‚Üí eso da el valor $z$.
* Pasamos ese $z$ por la funci√≥n sigmoide $\sigma(z)$, que lo convierte en una probabilidad entre 0 y 1.
* Si la probabilidad es mayor a un umbral (como 0.5), predecimos que s√≠ ocurrir√° el evento.

La sigmoide suaviza esa decisi√≥n y nos da una curva de probabilidad.

### **Multiclase**

Cuando hay m√°s de dos clases (por ejemplo, si el cliente puede ser de tipo A, B o C), usamos dos enfoques:

* **One-vs-Rest (OvR)**
    * Entrenamos un modelo para cada clase: por ejemplo, Clase A vs. no A, Clase B vs. no B, etc.


* **Softmax (regresi√≥n log√≠stica multinomial)**:
    * Aqu√≠ el modelo predice todas las probabilidades al mismo tiempo, usando esta f√≥rmula:

    $$
    P(y = k \mid X) = \frac{e^{z_k}}{\sum_{j=1}^{K} e^{z_j}} \quad \text{con } z_k = X^\top \beta_k
    $$

    * Esto asegura que todas las probabilidades sumen 1.
    * Cada clase tiene su propio vector de pesos $\beta_k$.

### **Funci√≥n de P√©rdida: `log_loss`**

La **regresi√≥n log√≠stica** aprende ajustando sus par√°metros para **minimizar el error entre las probabilidades que predice y los valores reales**.

Ese error se mide con una funci√≥n llamada **p√©rdida logar√≠tmica negativa** (`log_loss`), que penaliza m√°s fuertemente cuando el modelo est√° **muy seguro y se equivoca**.

**Para el caso binario:**

$$
\mathcal{L} = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(p_i) + (1 - y_i) \log(1 - p_i) \right]
$$

* Esta funci√≥n:

    - Da una p√©rdida **baja** si el modelo predice una probabilidad alta cerca del valor real.
    - Da una p√©rdida **alta** si el modelo predice una probabilidad alta hacia el lado equivocado.
    - Por eso es ideal para clasificaci√≥n probabil√≠stica: **no solo importa acertar, sino qu√© tan convencido est√°s al hacerlo**.

**Para el caso multiclase (con softmax):**

$$
\mathcal{L} = -\frac{1}{N} \sum_{i=1}^{N} \sum_{k=1}^{K} y_{ik} \log(p_{ik})
$$

* Donde:

    - $y_{ik}$ es 1 si la observaci√≥n $i$ pertenece a la clase $k$, y 0 en caso contrario.
    - $p_{ik}$ es la probabilidad que el modelo asign√≥ a la clase $k$ para esa observaci√≥n.


Aqu√≠, el modelo intenta **asignar la mayor probabilidad a la clase correcta**, penalizando cualquier distribuci√≥n equivocada.

En resumen: `log_loss` no solo mide si acertamos o no, sino **qu√© tan bien calibradas est√°n nuestras predicciones**. Un modelo que duda con frecuencia (predice 0.51 en lugar de 0.99) tendr√° m√°s p√©rdida, aunque acierte.

---

## <b>Supuestos del Modelo</b>

Para que la regresi√≥n log√≠stica funcione correctamente y produzca resultados confiables, se deben considerar los siguientes supuestos:

- **Relaci√≥n lineal** entre las variables independientes y el logit (log-odds) de la variable dependiente.  
  > *No se requiere linealidad con la variable respuesta directamente, sino con su log-odds.*

- **Independencia de las observaciones**.  
  > *Cada fila debe ser independiente. No es adecuado para datos dependientes (como series temporales o datos de panel sin ajustes).*

- **Ausencia de multicolinealidad severa** entre las variables predictoras.  
  > *Se recomienda revisar VIFs o usar t√©cnicas como PCA si hay correlaci√≥n fuerte entre predictores.*

- **Tama√±o de muestra suficiente**.  
  > *Se sugiere tener al menos 10 eventos por cada predictor para evitar overfitting.*

- **Ausencia de outliers influyentes o leverage points excesivos**.  
  > *Los outliers pueden distorsionar los coeficientes. Es recomendable revisar medidas como Cook's Distance o leverage.*

- **No hay errores de medici√≥n severos en las variables independientes**.  
  > *Se asume que los predictores son medidos con cierta precisi√≥n. El error en X puede afectar la estimaci√≥n.*

*A diferencia de la regresi√≥n lineal, la regresi√≥n log√≠stica **no asume normalidad ni homocedasticidad** de los residuos.*

---

## <b>Interpretaci√≥n</b>

Una vez entrenado el modelo de regresi√≥n log√≠stica, es clave **interpretar correctamente sus salidas**. A continuaci√≥n, se detallan los elementos que deben analizarse:

### **Coeficientes y log-odds**

Cada coeficiente $\beta_j$ representa el **efecto del predictor $x_j$ sobre el logaritmo del odds** (logit) de que ocurra el evento (por ejemplo, $Y = 1$).

$$
\text{logit}(p) = \log\left(\frac{p}{1 - p}\right) = \beta_0 + \beta_1 x_1 + \dots + \beta_p x_p
$$

- Si $\beta_j > 0$: a mayor valor de $x_j$, **mayor probabilidad** del evento.
- Si $\beta_j < 0$: a mayor valor de $x_j$, **menor probabilidad** del evento.
- Si $\beta_j = 0$: $x_j$ no tiene efecto sobre la respuesta.

### **Odds y Odds Ratio**

- **Odds**: se refiere a la raz√≥n entre la probabilidad de que ocurra el evento y la de que no ocurra:
  $$
  \text{odds} = \frac{p}{1 - p}
  $$

- **Odds Ratio** (OR): se interpreta como el cambio multiplicativo en los odds ante un incremento de 1 unidad en $x_j$:
  $$
  \text{OR}_j = e^{\beta_j}
  $$

> Ejemplo: Si $\beta_1 = 0.7$, entonces $e^{0.7} \approx 2.01$, lo que significa que un aumento de 1 unidad en $x_1$ **duplica los odds** del evento.

### **Probabilidades**

El modelo calcula una probabilidad para cada observaci√≥n:

$$
p_i = \frac{1}{1 + e^{-z_i}} = \frac{1}{1 + e^{-(\beta_0 + \sum \beta_j x_{ij})}}
$$

Esto se interpreta como la **probabilidad estimada** de que $Y = 1$ dado $X$.

### **Significancia estad√≠stica de los coeficientes**

Cada coeficiente $\beta_j$ tiene asociado:

- Un **error est√°ndar**
- Un **valor z**: $\dfrac{\beta_j}{SE(\beta_j)}$
- Un **valor p**: para evaluar si el efecto es significativo

> Un valor p < 0.05 indica que el predictor **tiene un efecto significativo** en el modelo.

### **Desvianza (Deviance)**

La **desvianza** mide el mal ajuste del modelo. Es an√°loga a la suma de cuadrados de errores en regresi√≥n lineal:

- **Desvianza del modelo completo**: 
  $$
  D = -2 \cdot \log(\text{verosimilitud del modelo})
  $$

- **Desvianza nula**: usando solo el intercepto  
- **Desvianza residual**: con todas las variables predictoras

> Un **buen modelo** reduce la desviaci√≥n residual respecto a la nula.

### **Pseudo R¬≤**

Como no se puede usar el R¬≤ tradicional, se emplean **versiones adaptadas**:

- **McFadden's $R^2$**:
  $$
  R^2_{\text{McFadden}} = 1 - \frac{\log L_{\text{modelo}}}{\log L_{\text{nulo}}}
  $$

- **Cox & Snell R¬≤**, **Nagelkerke R¬≤** (ajustado)

> Aunque no equivalen a un R¬≤ cl√°sico, **valores m√°s altos indican mejor ajuste relativo**.

### **En resumen:**

| Elemento          | Qu√© representa                                    |
|-------------------|----------------------------------------------------|
| $\beta_j$         | Efecto de $x_j$ sobre el log-odds                  |
| $e^{\beta_j}$     | Cambio en los odds (odds ratio)                   |
| Desvianza         | Mal ajuste del modelo                             |
| Pseudo $R^2$      | Calidad relativa del ajuste                       |
| p-valor           | Significancia del efecto de cada variable         |

---

## <b>Implementaci√≥n en `scikit-learn`</b>

```python
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(
    penalty='l2',
    dual=False,
    tol=1e-4,
    C=1.0,
    fit_intercept=True,
    intercept_scaling=1,
    class_weight=None,
    random_state=42,
    solver='lbfgs',
    max_iter=100,
    multi_class='auto',
    verbose=0,
    warm_start=False,
    n_jobs=None,
    l1_ratio=None
)

model.fit(X_train, y_train)
pred = model.predict(X_test)
proba = model.predict_proba(X_test)
```

---

## <b>Par√°metros Cruciales</b>


A continuaci√≥n, se explican los hiperpar√°metros m√°s importantes que afectan directamente el rendimiento, generalizaci√≥n y comportamiento de la regresi√≥n log√≠stica.

### **penalty ‚Äî Tipo de regularizaci√≥n**

La regularizaci√≥n **penaliza** los coeficientes del modelo para evitar que crezcan demasiado y se sobreajusten a los datos de entrenamiento.

- `'l2'` ‚Üí Ridge: penaliza los **cuadrados** de los coeficientes. Tiende a mantenerlos peque√±os pero no los lleva a cero.
- `'l1'` ‚Üí Lasso: penaliza los **valores absolutos**. Puede hacer que algunos coeficientes sean exactamente cero (selecci√≥n de variables).
- `'elasticnet'`: mezcla entre L1 y L2. Necesita que `l1_ratio` est√© definido.
- `'none'`: sin regularizaci√≥n. **Muy peligroso si tienes muchos predictores o poco data.**

> Cuanto m√°s fuerte la regularizaci√≥n, m√°s "conservador" ser√° tu modelo.

### **C ‚Äî Inverso de la fuerza de regularizaci√≥n**

Este es uno de los m√°s malentendidos. **`C` NO es coste ni penalidad directa. Es el inverso de la regularizaci√≥n**:

- **Valor bajo de `C`** ‚áí regularizaci√≥n fuerte ‚áí el modelo ajusta menos a los datos ‚áí **m√°s generalizaci√≥n**.
- **Valor alto de `C`** ‚áí regularizaci√≥n d√©bil ‚áí el modelo trata de ajustar m√°s exacto al entrenamiento ‚áí **mayor riesgo de sobreajuste**.

> `C = 1 / Œª` donde Œª es la fuerza de regularizaci√≥n.

> En pr√°ctica: prueba varios valores con validaci√≥n cruzada (por ejemplo, `C` en [0.01, 0.1, 1, 10, 100]).

### **solver ‚Äî Algoritmo de optimizaci√≥n**

El solver define **c√≥mo se entrena el modelo num√©ricamente**. Afecta:

- Velocidad
- Estabilidad
- Soporte para diferentes penalizaciones y multiclase

| Solver        | L1 | L2 | Multiclase  | Escala bien con grandes datos |
| ------------- |----|----|-------------|-------------------------------|
| `'liblinear'` | S√≠  | S√≠  | No (OvR)     | Lento en muchos datos         |
| `'lbfgs'`     | No  | S√≠  | S√≠ (softmax) | R√°pido y estable            |
| `'newton-cg'` | No  | S√≠  | S√≠           | Bien para softmax             |
| `'sag'`       | No  | S√≠  | S√≠           | Muy r√°pido con muchas filas   |
| `'saga'`      | S√≠  | S√≠  | S√≠           | Ideal para datos grandes + L1/L2 |

> Solo `'liblinear'` y `'saga'` soportan `penalty='l1'` o `elasticnet`.

### **multi_class ‚Äî Estrategia para multiclase**

Solo relevante si tienes m√°s de dos clases.

- `'auto'`: selecciona `'ovr'` o `'multinomial'` seg√∫n el `solver`.
- `'ovr'`: entrena un modelo por clase vs. el resto (One-vs-Rest).
- `'multinomial'`: entrena un solo modelo conjunto con softmax.  
    Mejor si las clases se superponen mucho.

> Usa `'multinomial'` + `solver='lbfgs'` o `'saga'` para mejores resultados.

### **class_weight ‚Äî Control del desbalance de clases**

Cuando una clase ocurre mucho m√°s que otra (por ejemplo, 90% vs 10%), el modelo puede **ignorar** la clase minoritaria.

- `None`: todas las clases tienen el mismo peso.
- `'balanced'`: ajusta los pesos autom√°ticamente seg√∫n la frecuencia de cada clase.
- `{0: w0, 1: w1}`: pesos personalizados si sabes cu√°nto penalizar cada clase.

> En clasificaci√≥n desbalanceada, `class_weight='balanced'` puede **mejorar mucho el recall** en la clase minoritaria.

### **Otros par√°metros √∫tiles pero no cr√≠ticos**

Si bien no afectan directamente el rendimiento predictivo, estos pueden ayudarte en casos espec√≠ficos:

- `max_iter`: Aumenta si el solver no converge.
- `tol`: Reduce si quieres mayor precisi√≥n en la convergencia.
- `fit_intercept`: Generalmente debe ser `True`.

**Resumen gr√°fico mental:**

| Par√°metro     | Afecta...                   | Cu√°ndo ajustarlo                        |
|---------------|-----------------------------|-----------------------------------------|
| `penalty`     | Qu√© coeficientes se penalizan | Para evitar overfitting o seleccionar variables |
| `C`           | Cu√°nta regularizaci√≥n aplicar | Cuando hay over/underfitting            |
| `solver`      | C√≥mo se entrena el modelo     | Seg√∫n tama√±o de datos y penalizaci√≥n     |
| `multi_class` | Estrategia para multiclase    | Cuando tienes m√°s de dos clases         |
| `class_weight`| C√≥mo trata el desbalance      | Siempre que tengas clases desbalanceadas |

---

## <b>Validaciones Num√©ricas Internas</b>

Cuando llamas al m√©todo `.fit()` del modelo de regresi√≥n log√≠stica en `scikit-learn`, se inicia un proceso interno de **optimizaci√≥n matem√°tica** para encontrar los mejores coeficientes.

### **¬øQu√© significa "entrenar" el modelo?**

Significa **encontrar los valores √≥ptimos de los coeficientes** ($\beta_0, \beta_1, ..., \beta_p$) que **minimizan la funci√≥n de p√©rdida** definida por el modelo.

### **¬øQu√© funci√≥n se minimiza?**

Se minimiza la **p√©rdida logar√≠tmica negativa** (`log_loss`), tambi√©n conocida como **verosimilitud negativa**:

- Para clasificaci√≥n binaria:

$$
\mathcal{L} = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(p_i) + (1 - y_i) \log(1 - p_i) \right]
$$

- Si hay regularizaci√≥n (seg√∫n `penalty` y `C`), se agrega un t√©rmino extra:

$$
\mathcal{L}_{\text{reg}} = \mathcal{L} + \lambda R(\beta)
$$

Donde $R(\beta)$ puede ser:
- $\sum \beta_j^2$ si `penalty='l2'`
- $\sum |\beta_j|$ si `penalty='l1'`

### **¬øQu√© hace internamente `.fit()`?**

1. **Inicializa** los coeficientes con valores peque√±os (aleatorios o ceros).
2. **Calcula gradientes** de la funci√≥n de p√©rdida respecto a cada coeficiente.
3. **Itera usando el solver elegido** (como `'lbfgs'`, `'liblinear'`, etc.) para actualizar los coeficientes en la direcci√≥n que minimiza la p√©rdida.
4. **Detiene el entrenamiento** cuando:
   - Se alcanza el n√∫mero m√°ximo de iteraciones (`max_iter`), o
   - La mejora es menor que la tolerancia (`tol`)

### **¬øQu√© devuelve al final?**

Despu√©s del ajuste, puedes obtener:

- `model.coef_`: los coeficientes $\beta_1, \dots, \beta_p$
- `model.intercept_`: el intercepto $\beta_0$
- `model.n_iter_`: n√∫mero de iteraciones realizadas
- `model.classes_`: las clases aprendidas

### **Importante:**

- Si el modelo **no converge**, puedes:
  - Aumentar `max_iter`
  - Usar un solver m√°s estable (`'lbfgs'`, `'saga'`)
  - Revisar escalado de variables

- Si est√°s usando **regularizaci√≥n**, el efecto depender√° de `C`, `penalty` y el tipo de solver.

### **En resumen**

Entrenar una regresi√≥n log√≠stica significa resolver un **problema de optimizaci√≥n num√©rica**, donde el objetivo es **maximizar la verosimilitud** (o minimizar la p√©rdida logar√≠tmica) y encontrar los coeficientes que mejor explican la relaci√≥n entre $X$ e $Y$.

---

## <b>Casos de uso</b>

Aunque hoy en d√≠a se prefieren modelos complejos como XGBoost, LightGBM o redes neuronales, la regresi√≥n log√≠stica sigue siendo **la mejor elecci√≥n** en ciertos escenarios.

### **Diagn√≥stico m√©dico (enfermo vs. sano)**

- Necesitas **interpretabilidad clara**: saber qu√© variables aumentan el riesgo.
- La regresi√≥n log√≠stica permite obtener **odds ratios**, ideales para publicaciones cl√≠nicas.

> Los m√©dicos necesitan confianza en el modelo, no solo predicci√≥n.

### **Cr√©dito y scoring financiero**

- **Regulaciones legales** exigen modelos interpretables.
- Permite explicar por qu√© se aprueba o rechaza un cr√©dito.
- Es **f√°cil de auditar** por entes reguladores.

> En banca, transparencia > precisi√≥n ciega.

### **Detecci√≥n de fraude (primera etapa)**

- √ötil como **modelo base r√°pido** en sistemas antifraude.
- Funciona bien cuando las **relaciones son lineales o log-odds**.
- Se puede escalar y mantener sin complejidad computacional.

> Luego puede reemplazarse por XGBoost, pero primero se parte por modelos simples.

### **Clasificaci√≥n de correos (spam vs. no spam)**

- Si el volumen de datos es muy alto, un modelo simple y r√°pido puede ser suficiente.
- Puede ser entrenado en tiempo real sin necesidad de GPUs ni infraestructura pesada.

> Perfecto para soluciones ligeras y reentrenamiento frecuente.

### **Predicci√≥n de abandono (churn)**

- Se busca **entender las causas del abandono** (interpretabilidad).
- El equipo de negocio puede accionar directamente sobre los coeficientes del modelo.

> Saber que "aumentar llamadas reduce churn" es m√°s √∫til que un AUC de 0.94 sin explicaciones.

### **¬øCu√°ndo *NO* usar regresi√≥n log√≠stica?**

- Cuando las relaciones entre variables y el target **no son lineales**.
- Cuando hay **mucha interacci√≥n o complejidad no capturada por logit**.
- Cuando **la precisi√≥n m√°xima es cr√≠tica** (por ejemplo, en detecci√≥n de fraude en tiempo real con millones de eventos).

### **Conclusi√≥n**

> La regresi√≥n log√≠stica no es anticuada: es **la opci√≥n correcta cuando necesitas transparencia, velocidad, estabilidad y explicaciones claras**.

---

## <b>Profundizaci√≥n matem√°tica</b>

Esta secci√≥n est√° dirigida a quienes desean comprender el **fundamento matem√°tico detr√°s del entrenamiento** de la regresi√≥n log√≠stica, m√°s all√° de la implementaci√≥n.

### **Derivada de la funci√≥n de p√©rdida (gradiente)**

Para clasificaci√≥n binaria, la funci√≥n de p√©rdida por observaci√≥n es:

$$
\mathcal{L}_i = -\left[ y_i \log(p_i) + (1 - y_i) \log(1 - p_i) \right]
$$

donde:

$$
p_i = \frac{1}{1 + e^{-z_i}}, \quad z_i = \beta_0 + \sum_{j=1}^{p} \beta_j x_{ij}
$$

El **gradiente respecto a un coeficiente $\beta_j$** es:

$$
\frac{\partial \mathcal{L}}{\partial \beta_j} = \sum_{i=1}^{N} (p_i - y_i) x_{ij}
$$

> Esto tiene un significado intuitivo: el gradiente es proporcional al **error de predicci√≥n multiplicado por el input correspondiente**.

### **Regularizaci√≥n L2 (Ridge)**

Agrega un t√©rmino cuadr√°tico a la funci√≥n de p√©rdida:

$$
\mathcal{L}_{\text{reg}} = \mathcal{L} + \lambda \|\beta\|_2^2 = \mathcal{L} + \lambda \sum_{j=1}^{p} \beta_j^2
$$

Esto **reduce la magnitud** de los coeficientes, previene overfitting y favorece soluciones m√°s estables num√©ricamente.

> üîß En `scikit-learn`, se usa $\lambda = \dfrac{1}{C}$, donde `C` es el hiperpar√°metro de regularizaci√≥n.

### **Regularizaci√≥n L1 (Lasso)**

Agrega la **suma de valores absolutos** en lugar del cuadrado:

$$
\mathcal{L}_{\text{reg}} = \mathcal{L} + \lambda \|\beta\|_1 = \mathcal{L} + \lambda \sum_{j=1}^{p} |\beta_j|
$$

Esto favorece **soluciones sparse**, es decir, con coeficientes exactamente cero.  
Muy √∫til para **selecci√≥n autom√°tica de variables**.

> La funci√≥n no es diferenciable en cero, por lo que requiere m√©todos especiales como `'liblinear'` o `'saga'` para su optimizaci√≥n.

### **Gradiente completo con regularizaci√≥n**

- Para **L2**:

$$
\frac{\partial \mathcal{L}_{\text{reg}}}{\partial \beta_j} = \sum_{i=1}^{N} (p_i - y_i) x_{ij} + 2\lambda \beta_j
$$

- Para **L1**:  
El gradiente se reemplaza por un **subgradiente**, ya que $|\beta_j|$ no es diferenciable en cero:

$$
\frac{\partial \mathcal{L}_{\text{reg}}}{\partial \beta_j} = \sum_{i=1}^{N} (p_i - y_i) x_{ij} + \lambda \cdot \text{sign}(\beta_j)
$$

donde:

$$
\text{sign}(\beta_j) =
\begin{cases}
1 & \text{si } \beta_j > 0 \\
-1 & \text{si } \beta_j < 0 \\
\in [-1, 1] & \text{si } \beta_j = 0
\end{cases}
$$

### **Nota sobre convergencia y m√©todos num√©ricos**

- La regresi√≥n log√≠stica **no tiene soluci√≥n cerrada** como la regresi√≥n lineal.
- El proceso de ajuste implica **algoritmos iterativos**:
    - `'lbfgs'`, `'newton-cg'`: usan gradiente + Hessiano (segunda derivada).
    - `'liblinear'`, `'saga'`: m√°s eficientes para penalizaci√≥n L1.

### **Conclusi√≥n**

> El coraz√≥n de la regresi√≥n log√≠stica es la **minimizaci√≥n de una funci√≥n convexa**, y su entrenamiento requiere comprender derivadas, regularizaci√≥n y gradientes. Esta base te permite extenderte a modelos m√°s complejos como redes neuronales o XGBoost con confianza.

---

## <b>Recursos para profundizar</b>

**Libros**  
- *The Elements of Statistical Learning* ‚Äì Hastie, Tibshirani, Friedman  
- *An Introduction to Statistical Learning* ‚Äì James et al.  
- *Pattern Recognition and Machine Learning* ‚Äì Bishop  

**Cursos**  
- Andrew Ng ‚Äì Coursera ML  
- MIT ‚Äì Statistical Learning  
- FastAI o YouTube (StatQuest)

**Documentaci√≥n oficial**  
- [scikit-learn: LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)

---
